---
title: "Numero Introduction"
author: 
- name: Song Gao
  affiliation:
  - &sahmri South Australian Health And Medical Research Institute, Adelaide, Australia
  - &uni University of Adelaide, School of Biological Sciences, Adelaide, Australia
  email: song.gao@sahmri.com  
- name: Stefan Mutter
  affiliation: 
  - *sahmri 
  - *uni
- name: Ville-Petteri Mäkinen
  affiliation: 
  - *sahmri
  - *uni
  - Computational Medicine, Institute of Health Sciences, Faculty of Medicine, University of Oulu, Finland
  
date: "`r doc_date()`"
package: "`r pkg_ver('Numero')`"
output: BiocStyle::html_document2
bibliography: Numero.bib
csl: apa-old-doi-prefix.csl
abstract: >
  Numero is a multivariate statistical framework that creates a two dimensional map out of a multi-dimensional input. The framework uses self-organising maps. Its main purpose is to easily visualise and consequently support the identification of subgroups of samples/individuals. The framework is especially useful but not limited to data-driven discovery of epidemoilogically, clinically and/or biologically relevant subtypes and subgroups. 
vignette: >
  %\VignetteIndexEntry{Numero Introduction}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}  
---

<!--
%% \VignetteEngine{knitr::knitr}
-->
```{r, echo = FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = "#>")
```
```{r, echo = FALSE, results='asis'}
BiocStyle::markdown()
BiocStyle::markdown(css.files = c('custom.css'))
```

# Prerequisites and Installation

`r Biocpkg('Numero')`  requires `r CRANpkg('Rcpp')`. To install `r Rpackage('Rcpp')`, use the command:

```{r, eval=FALSE}
install.packages( "Rcpp" )
```

Amongst others, there is a vignette that gives a general overview of `r Rpackage('Rcpp')` and one that answers frequently asked questions.

```{r, eval=FALSE}
vignette('Rcpp-introduction')
vignette('Rcpp-FAQ')
```

After installing `r Rpackage('Rcpp')`, `r Rpackage('Numero')` can be installed either via Bioconductor

```{r,eval=FALSE}
## try http:// if https:// URLs are not supported
source("https://bioconductor.org/biocLite.R")
biocLite("Numero")
```

or by downloding the file and using the following command:

```{r, eval=FALSE}
install.packages( "<download_dir>/<Numero file>.tar.gz", type="source", repos=NULL )
```

```{r setUpLibrary, eval=TRUE, include=FALSE}
library(Numero)
```

# Introduction

`r Biocpkg('Numero')` is a multivariate statistical framework that creates a two dimensional map out of a multi-dimensional input. The framework uses self-organising maps (SOMs) which are a well-established unsupervised learning algorithm [@kohonen_som]. Previous versions of this software (written for MatLab) were successfully used on range of metabolomics data sets for various diseases [@makinen_1h_2008; @makinen_metabolic_2008; @tukiainen_multi-metabolite_2008; @kumpula_characterization_2010; @bernardi_new_2010; @wurtz_characterization_2011; @makinen_metabolic_2012; @kuusisto_interplay_2012; @makinen_triglyceride-cholesterol_2013]. The main purpose of the framework is to easily visualise and consequently support the identification subtypes of samples/individuals. The framework is especially useful but not limited to data-driven discovery of epidemoilogically, clinically and/or biologically relevant subtypes and subgroups.  

## How to use a self-organsing map (SOM)

Like all learning algorithms, the use of a SOM requires a staged approach: training the SOM, matching samples and visualise the results. You can use the exact same set of samples for training and matching. However, you will not be able to calculate statistical significance for these maps and they might be overly confident. Alternatively, there are other options for your study design. In this vignette, we propose using all samples for training and testing, but limit the training to some of the measured variables. A common example would be to train `r Rpackage('Numero')` with the biomarker data (e.g. serum measurements) and test it with that data and disease data (e.g. diabetes diagnosis). However, our framework is not limited to such a setup. Other splits of training and matching are possible but not part of this introduction. In general, `r Rpackage('Numero')` allows to use a subset of samples/individuals and/or a subset of features for training and matching. 

An introduction to the SOM and in particular circular SOM as used in this software can be found the in supplements (Supporting Information 1 (p.2-5)) from @makinen_metabolic_2012. Another introduction to the SOM (with rectangular maps) is in the supplements from @makinen_1h_2008.

`r Rpackage('Numero')` has been designed to be trained with numerical data. It will accept binary data for training but the maps might be harder to interpret if the majority of training variables are binary. Testing can be done with both kind of data.

## Subtypes and subgroups {#subtypesSubgroups}

`r Rpackage('Numero')` positions samples/individuals on a two dimensional map so that samples/individuals that are similar in the multi-dimensional space are closer together on the two dimensional map. The samples/individuals that are most similar to one another form a neighbourhood on the map. These neighbourhoods are summarised in a subtype. Each sample/individual is mapped to exactly one subtype. The number of neighbourhoods/subtypes is an (indirect) input parameter. Our maps are circular to avoid boundary effects of rectangular maps. Thus, the user specifies the radius of the map. The number of subtypes depends on the radius. 

Upon visual inspection of the maps, user can combine several subtypes into subgroups. It is important to keep in mind the difference between a subtype and a subgroup. Figure 1A shows a circular example map with 40 subtypes (created by setting the radius to 3). They are numbered from 1 to 40. Figure 1B shows a trained SOM with a pattern. The subtypes on the right side of the map are different from the others and thus, they can be grouped into a subgroup. This subgroups is made up of the samples/individuals that belong to subtypes 2, 3, 12, 13, 14, 22, 23, 24, 39 and 40.

![[Figure 1. ](#fig1) Subtypes and subgroups](subtypesSubgroups.png)

A *subtype* is a typical but theoretical sample/individual that summarises a (neighbourhood) group of samples/individuals. It is not necessarily the same as one of the samples/individuals it represents or their averages as in a SOM framework a subtype is also influenced by neighbouring subtypes.

A *subgroup* is a grouping of one but most likely multiple subtypes. It averages the information of the all samples/individuals that had been mapped to these subtypes. Most importantly, it is not the average of its subtypes but of its underlying samples/individuals. Subgroups can be defined visually from the map or programmatically from `r Rpackage('Numero')` output. See the section on [interpretation](#interpretation) for more information. 


## Statistical significance

With a SOM, the main difficulty comes from the statistical ambiguity of the map; the algorithm finds a map configuration for random as well as “true” data, so it is crucial to validate the observations by statistical testing or equivalent measures. `r Rpackage('Numero')` uses permutations to calculate statisictal significance. The number of permutations can be set by the user. The defaults 10,000. 

Note that since the training variables are directly responsible for the sample mapping, they all have  non-meaningful p-values, which cannot be used for results interpretation. For more information, look at the section on [estimating map statistics](#stats) that introduces our permutation function *nroPermute*


# The `r Rpackage('Numero')` pipeline

`r Rpackage('Numero')` operates as a pipeline: pre-processing the data, training the model, matching and visualisation. The pre-processing step is not an integral part of `r Rpackage('Numero')` as it can be done natively in R. However, we provide an example in the [pre-processing section](#pre). 

Table 1 shows the complete pipeline. We will explain each function with the use of an example analysis in the [next section](#howto). There is a link in the table that directly jumps to the corresponding explanation. The list in the table is exhaustive. These are all functions in the `r Rpackage('Numero')` package.

Function | Part of pipeline | Short description 
---------|-----------------------|----------------------
*nroMatrix*|[Load the data](#load)|Import a data matrix from a tab-delimited text file
*nroKmeans*|[Setup  and train the SOM](#setup)|Create the initial seed profile of the SOM
*nroKoho*|[Setup  and train the SOM](#setup)|Create the SOM
*nroTrain*|[Setup  and train the SOM](#setup)|Adapt the SOM to a set of multivariable data
*nroMatch*|[Match individuals/samples](#match)|Compares the multivariate samples to a SOM and determines their location
*nroPermute*|[Estimate map statistics](#stats)|Estimate the statistical significance for a regional pattern using permutations
*nroAggregate*|[Colourise maps and save figures](#colour)|Estimate regional aggregates based on assigned map locations
*nroColorize*|[Colourise maps and save figures](#colour)|Assign colors to subtypes
*nroLabel*|[Colourise maps and save figures](#colour)|Optimise the selection of labels for subtypes
*nroCircus*|[Colourise maps and save figures](#colour)|Create a Scalable Vector Graphics (SVG) code for a map
*nroFigure*|[Colourise maps and save figures](#colour)|Save a map to a Scalable Vector Graphics (SVG) file

Table: Table 1. The functions of the `r Rpackage('Numero')` pipeline.

# How to use the `r Rpackage('Numero')` pipeline {#howto}

This section gives a detailed example of how to do analysis using this package. `r Rpackage('Numero')` is designed as a pipeline and we will step through the pipeline from start to end.

## Example dataset
The example dataset is a smaller version of a publically available dataset [@makinen_1h_2008] on type 1 diabetes patients. Our version of the dataset contains `r nrow(nroMatrix(system.file("extdata", "finndiane_dataset.txt", package = "Numero"), keyvars = "INDEX"))` individuals and `r ncol(nroMatrix(system.file("extdata", "finndiane_dataset.txt", package = "Numero"), keyvars = "INDEX"))` columns with data on these individuals. 

```{r showReadme, eval = TRUE, echo=FALSE, comment=''}
#read in README file
readmeFile <- system.file("extdata", "README.txt", package = "Numero")
myText <- readLines(readmeFile)

#only show the relevant portion of the README file, if it fails show all
myMin <- max(which(myText == 'Baseline data:'),0)
myMax <- min(which(myText == 'Missing values are shown as \'NaN\'.'),length(myText))
myText <- myText[myMin:myMax]

#display results
cat(myText, sep = '\n')
```

It contains five biomarkers measured at baseline that are important with regards to type 1 diabetes. These are the urinary albumin excretion rate and the serum concentrations of triglycerides, total cholesterol, HDL2 cholesterol and creatinine. We also know age, sex and the diabetes duration and whether there have been complications or co-morbidities e.g. diabetic retinopathy, diabetic kidney disease, macrovascular disease or metabolic syndrome at baseline. At follow-up we know which individuals had passed away.

The aim of our data-driven analysis will be to find vulnerable subgroups in these individuals with type 1 diabetes based on the interaction of five biomarkers. One of the advantages of `r Rpackage('Numero')` is that it can handle a large number of risk factors. For this example we limited ourselves to five biomarkers.

## Load the data {#load}
First we need to load the data into a matrix using the *nroMatrix* function. The data has to be stored in a tab-delimited text file. In our example, the *INDEX* column contains the patient identifier. Be declaring it in *keyvars*, it will be automically removed from the analysis.
```{r setUpExample, eval=TRUE}
exampleFile <- system.file("extdata", "finndiane_dataset.txt", package = "Numero")
db <- nroMatrix(exampleFile, keyvars = "INDEX")
```

Second, we need to define our training set for the SOM. Individuals will be arranged on the tow dimensional map depending on how similar their features from the training set are. `r Rpackage('Numero')` allows to either choose a subset of features, or samples, or both as a training set. In our case, we chose all individuals and the five biomarkers as we are interested in disease and survival subgroups.
```{r preprocess1, eval=TRUE}
# Select training variables.
trvars <- c("uALB_log", "TG_log", "CHOL", "HDL2C", "CREAT_log")
trdata <- db[,trvars]
```


## Pre-processing {#pre}
Pre-processing the data is an important step. However, it is not an integral part of `r Rpackage('Numero')` as pre-processing support is already provided in *R*.

Here, we standardise the data to eliminate differences in measurement units. Otherwise, one biomarker might unduly dominate the results. We recommend standardisation prior to using our package. In addition, we adjust the data according to sex which is also a common pre-processing step. When you conceive your own study, it is important to execute the appropriate pre-processing step in order to have valid results.
```{r preprocess2, eval=TRUE}
# Separate men and women.
men <- which(!(db[,"MALE"] == 0))
women <- which(db[,"MALE"] == 0)

# Standardise training data to reduce gender differences
# and to eliminate differences in measurement units.
trdata[men,] <- scale.default(trdata[men,])
trdata[women,] <- scale.default(trdata[women,])
```

## Setup  and train the SOM {#setup}

The first step is to initialise the SOM. In `r Rpackage('Numero')` we use the centroids of k-Means clusters on the training data for that purpose. The function *nroKmeans* provides this information. The user can choose the number of centroids. 

Then *nroKoho* initialises the SOM using the centroids and a user defined radius for the circular map. The radius controls the resolution of the SOM. Here, we choose 3 centroids and set the radius to 3. Figure 1A from the [subgroup section](#subtypesSubgroups) shows a SOM of radius 3.

```{r setup1, eval=TRUE}
# Use K-means clustering to determine seed profiles for the SOM. 
km <- nroKmeans(x=trdata, k = 3)
sm <- nroKoho(seeds=km$centroids, radius = 3)
```

Training of the SOM is now straight-forward. Just input the initialised SOM and the training data into the *nroTrain* function. `r Rpackage('Numero')` has been designed to be trained with numerical data. It can include binary data coded as 0 and 1. Training solely on binary data might produce maps that are hard to interpret.

```{r setup2, eval=TRUE}
# Train the SOM with the standardized data.
sm <- nroTrain(som=sm, x=trdata)
```

## Match individuals/samples {#match}

The next step after training is to match all individuals/samples to exactly one subtype. This subtype is the best matching subtype (or in the code referred to as best matching unit BMU) and it is found by the *nroMatch* function. The function takes the SOM and the data as input. It outputs a data frame with a row for each sample and three columns: BMU contains the best matching subtype/unit and two columns QUALITY and RDATA that can be used to assess the quality of the SOM. We discuss the two quality column in their own section on [SOM qauality](#qm) as they are not an integral part of the pipeline. For now, the column of interest is the best matching subtype one.

```{r match1, eval=TRUE}
# Find best-matching subtypes for all samples.
matches <- nroMatch(som=sm, x=trdata)
```

As the output below shows, the individual in the first row is matched to subtype `r head(matches$BMU)[1]`, the individual in the second row to subtype `r head(matches$BMU)[2]`, etc.

```{r match2, eval=TRUE}
# Show the first best-matching subtypes
head(matches$BMU)
```

## Estimate map statistics {#stats}

The next step in the pipeline is to estimate the significance of a SOM pattern e.g. whether significant differences between subtypes on the map exist. For this purpose, we use permutations and the *nroPermute* function. The permute function takes the SOM, the best matching subtypes, the values of the variable under consideration and the maximuum number of permutations. The default for this number is 10,000. *nroPermute* permutes the best-matching units to calculate the statistics.

```{r stats1, eval=TRUE}
# Determine statistics for all variables.
stats <- matrix(NA, ncol(db), 5)
rownames(stats) <- colnames(db)
for( vname in colnames(db) ) {
    
    # Check if a training variable.
    nsim <- NA
    pos <- match(vname, trvars)
    if(is.na(pos)) nsim <- 10000
 
    # Estimate dynamic range of variation.
    tmp <- nroPermute(map=sm, x=db[,vname], bmus=matches$BMU, n=nsim)
    colnames(stats) <- colnames(tmp)
    stats[vname,] <- as.matrix(tmp)
}
```

In this example, the output of *nroPermute* is saved in a data frame called stats. It contains five columns: P is a parametric estimate for statistcal significance. FREQ is the frequency-based estimate for statistical signicance, Z is the estimated z-score of how far the observed map plane is from the average randomly generated layout, NDATA indicates how many data values were used, and NSIM tells the number of completed permutations.

```{r stats2, eval=TRUE}
print(stats)
```

## Colourise maps and save figures {#colour}

Before we can colour the maps according to each subtype's value, we need to determine a suitable colour range so that maps with a significant pattern (e.g. siginifcant differences between subtypes) can easily be differentiated from maps with insignificant differences among subtypes.

### Define the colour range for all SOMs

The significance (e.g. P-values and Z-scores) of the differences among subtypes for all variables is encoded into one dynamic colour range for all SOM maps.

```{r colour1}
# Determine suitable dynamic color range across all variables.
# The middle point between the mean training variable score and
# the strongest evaluation variable usually works well.
tr <- which(is.na(stats[,"P"]))
ev <- which(stats[,"P"] >= 0.0)
zbase <- 0.5*(mean(stats[tr,"Z"], na.rm=TRUE)
              + max(stats[ev,"Z"], na.rm=TRUE))

# Make sure the base scale is large enough to prevent non-significant
# signals from getting bright colors.
zbase <- max(zbase, 2.0)

# Set color scale factors. Ideally, these should all be between
# 0 and 1. In practice, it is often better to adjust the scale
# so that the strongest evaluation variable gets a reasonable
# value (e.g. between 0.5 and 1.0), whereas the training variables
# can be over 1.
amplitudes <- stats[,"Z"]/zbase
```

```{r colour2, echo= FALSE}
#if the dataset has changed and has different column names, default back to using all columns
myNames <- c("T1D_DURAT")
if(length(which(myNames %in% colnames(db))) != length(myNames)){
  myNames <- colnames(db)
}
for( vname in myNames) {
     plane <- nroAggregate(map=sm, x=db[,vname], bmus=matches$BMU)
     clrs <- nroColorize(values=plane, amplitude=amplitudes[vname])
     labs <- nroLabel(map=sm, values=plane)
     pval <- stats[vname,"P"]
     ttxt <- vname
     if(is.na(pval) == FALSE) {
         ttxt <- sprintf("%s, P = %.2e", vname, pval);
     }
     smfig <- nroCircus(map=sm, colors=clrs, labels=labs, title=ttxt)
     fpath <- paste(vname, ".svg", sep="")
     nroFigure(file=fpath, scene=smfig)
}
```

### Define the actual colour for each subtype

After having defined the colour range for all SOMs, we create one SOM for each feature indepdendent whether the feature has been used in training or testing. As you can see in the code below, we simply loop through all the features: `r colnames(db)`.

First *nroAggregate* estimates the subtypes values for each given feature given the SOM *sm*, the actual values of the feature from the dataset and the best matching units/subtypes *BMU*. The actual colour of a particular subtype in a particular map is simply based on the subtype's value for the variable under consideration. Because of matching, it is possible to train the SOM on standardised and adjusted values but to colour the SOM according to the true original data value. An example for this is HDL2 cholesterol in Figure 3C in the [results section](#visual). Therefore, the parameter *x* is set to the original data vector and not the standardised and adjusted training vector.

*nroColorize* chooses that colour given the subtype values and the colour range.

The helper function *nroLabel* places a few labels (the subtype values) on the map so that the map colours can be interpreted and put into context. Without using *nroLabel*, the users would not know which colour correspond to which value.

In the next step we create the *svg* file with *nroCircus*. As you can see in the code below, we add a title and the p-value to the map output. We recommend that when using Numero, as this information is essential when interpreting the map. Note, the p-value can only be calculated for features that haven't been used in training.

Lastly, *nroFigure* saves the *svg* content to a file.

```{r colour3, eval=FALSE}
# Process each variable separately. Note that to make the color scales
# comparable, all the statistics had to be estimated beforehand.
for( vname in colnames(db) ) {

     # Estimate subtype values.
     plane <- nroAggregate(map=sm, x=db[,vname], bmus=matches$BMU)
     
     # Determine subtype colors.
     clrs <- nroColorize(values=plane, amplitude=amplitudes[vname])

     # Determine which subtype labels should be shown.
     labs <- nroLabel(map=sm, values=plane)
     
     # Create a vector graphics object.
     pval <- stats[vname,"P"]
     ttxt <- vname
     if(is.na(pval) == FALSE) { # add p-value for evaluation variables
         ttxt <- sprintf("%s, P = %.2e", vname, pval);
     }
     smfig <- nroCircus(map=sm, colors=clrs, labels=labs, title=ttxt)
     
     # Save figure.
     fpath <- paste(vname, ".svg", sep="")
     nroFigure(file=fpath, scene=smfig)
}

```

This is the end of the analysis pipeline. An example map for type 1 diabetes duration can be found in the next [section](#interpretation). Now you need to interpret the results and we discuss this in the next [section](#interpretation) as well.

## Results and a possible subgroup interpretation {#interpretation}
Figure 2 shows the resulting SOM for the type 1 diabetes duration that had been saved by *nroFigure*.

![[Figure 2. ](#fig2) SOM for type 1 diabetes duration](T1D_DURAT.svg)

Above the map, it shows the name of the variable and its p-value. We can see that the pattern in the map is highly significant. Subtypes with a shorter diabetes duration are all in the bottom left area of the map. For convenience when repeating experiments, the output also includes a timestamp at the bottom.

### Analysing subgroups visually {#visual}

The interesting part in the analysis is now to compare different maps and define subgroups. Thanks to the map we can do this visually and this is a major advantage of the framework. It also possible to do it programmatically and we well discuss this later in this [section](#progInterpretation). 

Figure 3 shows our example subgroup analysis. This is not the only possible subgrouping for our results. Therefore, subgrouping is an exciting expert work.

![[Figure 3. ](#fig3) Subgroups in our type 1 diabetes examples](subgroupingExample.png)

Our subgrouping here is based on two maps: the one for type 1 diabetes duration and creatinine (Figure 3A). This results in three subgroups. One with a lower diabetes duration and lower creatinine (Subgroup *Shorter Duration*) on the left side, one with a longer diabetes duration and high creatinine (Subgroup *High Creatinine*) at the top of the map and one with a longer diabetes duration and low creatinine (Subgroup *Low Creatinine*) on the lower right. Note as creatinine levels were used in training, the map does not show a p-value. Now that the subgroups are defined and we know which subtypes belong to a subgroup, you can go back into the SOM output and calculate averages for each variable and subtype.

We are now interested how our three subgroups do in terms of disease and whether they were deceased at follow up (Figure 3B). We can see that Subgroup *High Creatinine* was likely to also have diabetic kidney disease. We can also see that a long diabetes duration has not necessarily led to kidney disease as Subgroup *Low Creatinine* had a longer duration of type 1 diabetes but also lower percentages of kidney disease. However, it is Subgroup *Shorter Duration* that was the least affected. Looking at survival, Subgroup *High Creatinine* showed the highest percentage of deceased individuals and the other two subgroups had much lower rates.

We can also compare our subgroups to ther biomarkers. Figure 3C shows an example for cholesterol in high density lipoprotein 2 (HDL2). We can see that Subgroup *Low Creatinine* had high HDL2 cholesterol levels especially compared to Subgroup  *High Creatinine* which also had a higher mortality.

Figure 3D shows another nice property of having visual maps. As explained, the data was adjusted for sex prior to the analysis. A successful adjustment means that there are no patterns on the map for sex. Looking at the SOM for male, we cannot see any pattern and the p-value for the SOM is not significant at the 0.05 level either.

### Analysing subgroups programmatically {#progInterpretation}
So far, we have compared maps visually and defined subgroups after such visual inpsection, but it is possible to compare the maps programmatically.


First, we define subgroups for Creatinine (subtype level in the 85 percentile) and HDL2 cholesterol (subtype level in the 75 percentile)
```{r progEval1, eval=TRUE}
# Find subtypes with high values of serum creatinine.
plane <- nroAggregate(map=sm, x=db[,"CREAT_log"], bmus=matches$BMU)
hiCREAT <- which(plane > quantile(plane, 0.85, na.rm=TRUE))
reserved <- hiCREAT
print(hiCREAT)

# Find subtypes with high HDL2 cholesterol.
plane <- nroAggregate(map=sm, x=db[,"HDL2C"], bmus=matches$BMU)
hiHDL <- which(plane > quantile(plane, 0.75, na.rm=TRUE))
hiHDL <- setdiff(hiHDL, reserved)
reserved <- union(reserved, hiHDL)
print(hiHDL)
```

We would continue choosing subtypes until all subtypes belong to exactly on subgroup. This can also be checked by R.
```{r progEval2, eval=TRUE}
# Check that all subgroups are distinct.
pooled <- c(hiCREAT, hiHDL)
if(length(unique(pooled)) != length(pooled)) {
    warning("Overlapping subgroups selected.")
}
if(length(pooled) != nrow(sm$topology)) {
    warning("Incomplete subgroups selected.")
}
```
In our case, we would have to continue to define further subgroups or change rthe definition of the existing subgroups.

Finally, we can add the subgroup information back into the dataset.
```{r progEval3, eval=FALSE}
# Assign data to subgroups.
db <- data.frame(INDEX=rownames(db), SUBGROUP="",
                 db, stringsAsFactors=FALSE)
db[which(match(matches$BMU, hiCREAT) > 0), "SUBGROUP"] <- "hiCREAT"
db[which(match(matches$BMU, hiHDL) > 0), "SUBGROUP"] <- "hiHDL"
```

# Checking the quality of maps {#qm}
`r Rpackage('Numero')` provides in-built ways to quickly and visually intuitively check the maps. They are built upon the output of the *nroMatch* function. As explained earlier, it returns a data frame with the best matching subtypes but also 2 quality columns that we can visualise in the following.

As a pre-requisite, you need the output from *nroMatch*. But then it simply follows the main pipeline using the functions *nroAggregate*, *nroColorize*, *nroLabel*, *nroCircus* and finally *nroFigure* to store the results. There is no need to define a colour range. 

We have three quality measures: [sample hisogram](#qm1), [matching quality](#qm2) and [coverage](#qm3). Except for the map title and the file name, *nroColorize*, *nroLabel*, *nroCircus* and *nroFigure* are used in exactly the same way for all three measures. The only difference is the use of the *nroAggregate* function.

## Sample distribution over the SOM {#qm1}

You can use the `r Rpackage('Numero')` pipeline to visiualise the distribution of individuals/samples over the map. For this purpose, do not provide a numeric vector to *nroAggregate* (the x parameter), just provide the SOM and the best matching subtypes. 

```{r quality1, eval=TRUE}
# Visualise sample histogram on the map to verify even distribution.
plane <- nroAggregate(map=sm, bmus=matches$BMU)

#the palette parameter is optional
clrs <- nroColorize(values=plane, palette="fire")
labs <- nroLabel(map=sm, values=plane)
smfig <- nroCircus(map=sm, colors=clrs, labels=labs,
                   title="Data histogram")
nroFigure(file="histogram.svg", scene=smfig)
```

Ideally, the distribution should be relatively equal. If there are areas on the map with only a few individuals, interpretation of that area might be more difficult.


Figure 4 shows that in our example a subtype is the representation of 12 to 18 individuals and the distribution is relatively equal with a higher density in the bottom left corner.

![[Figure 4. ](#fig4) Histogram of sample/individual distribution on the example SOM](histogram.svg)

## Matching quality {#qm2}

To assess the quality of the matching, `r Rpackage('Numero')` compares the overall mean training error to the error for each subtype. If the overall mean training error is the same as the subtype's training error the quality measure is 1. If the subtype's training error is smaller than the mean training error, than the quality measure is smaller than 1, otherwise it is greater than 1. This data is calculated in *nroMatch* and saved in the output column called QUALITY

Thus, use this QUAILTY column as numeric input for *nroAggregate* (x parameter) together with the SOM and the best matching subtypes.

```{r quality2, eval=TRUE}
# Visualise matching quality.
plane <- nroAggregate(map=sm, bmus=matches$BMU, x=matches$QUALITY)

#the palette parameter is optional
clrs <- nroColorize(values=plane, palette="fire")
labs <- nroLabel(map=sm, values=plane)
smfig <- nroCircus(map=sm, colors=clrs, labels=labs,
                   title="Match quality")
nroFigure(file="quality.svg", scene=smfig)
```

Figure 5 shows the quality of our example SOM.

![[Figure 5. ](#fig5) Quality measure for each subtype](quality.svg)

## Subtype coverage {#qm3}
The coverage map indicates for each subtype how much of data has been available. Ideally, 100% (represented by 1.0) of the data has been available but missing values in the dataset might have reduced that number. This visiulation shows whether there are subtypes that are suffering more than others from missing data.

You will need to feed the RDATA output of the *nroMatch* function together with the SOM and the best matching subtypes into *nroAggregate*.

```{r quality3, eval=TRUE}
# Visualise the amount of data available per subtype.
plane <- nroAggregate(map=sm, bmus=matches$BMU, x=matches$RDATA)

#the palette parameter is optional
clrs <- nroColorize(values=plane, palette="fire")
labs <- nroLabel(map=sm, values=plane)
smfig <- nroCircus(map=sm, colors=clrs, labels=labs,
                   title="Data coverage")
nroFigure(file="coverage.svg", scene=smfig)
```

As Figure 6 shows, there are some missing values in our dataset but we still achieve good coverage in each subtype.

![[Figure 6. ](#fig6) Coverage map for the SOM subtypes](coverage.svg)

# References



